{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've covered many of the mechanics of pandas, I want to stop and talk for a moment about data types and scales. We've already seen that pandas supports a number of different computational data types such as strings, integers, floating point numbers. What this doesn't capture is what we call the scale of the data. Let's say that we have got a DataFrame of students and their academic levels such as being in grade one, grade two, and grade three. Is the difference between a student in grade one and a student in grade two the same as the difference between a student in grade eight and one grade nine? Or maybe let's think about final exam scores these students might get on assignments. Is the difference between an A and an A- the same as the difference between an A minus and a B plus? So the University of Michigan, at least, the answer is often no, at least not when you're converting this to a percentage-based scale. \n",
    "\n",
    "We've intuitively seen some different scales. As we move through data cleaning and into statistical analysis and machine learning, it's important to clarify our knowledge and terminology. As a data scientist, there's at least four different scales that's worth knowing about, and I want to talk about those now. \n",
    "1. The first is the ratio scale. In the ratio scale, the measurement units are equally spaced and mathematical operations such as subtraction, division, and multiplication are all valid. Good examples of the ratio scale might be height and weight. \n",
    "2. The next scale is the interval scale. In the interval scale, the measurement units are equally spaced, like the ratio scale, but there's no clear absence of value. That is, there isn't a true zero, and so operations such as multiplication and division are not valid. An example of the interval scale might be the temperature as measured in Celsius or Fahrenheit since there's never an absence of temperature, and zero degrees is actually a meaningful value itself. The direction on a compass might be another good example, where zero degrees on the compass doesn't indicate a lack of direction, but instead describes a direction itself. For most of the work that you'll be doing with data mining, the differences between the ratio and interval scales might not be clearly apparent or important to the algorithm that you're to apply, but it's important to have this distinction clear in your mind when applying advanced statistical tests. \n",
    "3. The next scale to understand is the ordinal scale. In the ordinal scale, the order of values is important, but the differences between the values are not equally spaced. Here the grading method that is used in many classes at the University of Michigan is a great example, where letter grades are given with pluses and minuses, but when you compare this to a percentage value, you see that a letter by itself covers four percent of the available grades, and then a letter with a plus or minus is usually just three percent of the available grades. Based on this, it would be odd if there were as many students who received an A plus or an A minus as there was who received a straight A, assuming, of course, that we expect each percentage point in a course to be uniformly likely to occur. Ordinal data is very common in machine learning and sometimes can be a bit of a challenge to work with. \n",
    "4. The last scale I'll mention is the nominal scale, which is often just called categorical data. Here the names of teams in a sport might be a good example. There are a limited number of teams, but changing their order or applying mathematical functions to them is meaningless. Categorical values are very common and we generally refer to categories where there are only two possible values as binary categories. \n",
    "\n",
    "So why did I stop talking about pandas and jump into this discussion of scale? Well, given how important they are in statistics and machine learning, pandas has a number of interesting functions to deal with converting between measurement scales. Let's start first with nominal data, which in pandas is called categorical data. Pandas actually has a built-in type for categorical data, and you could set a column of your data to categorical simply by using the astype method. Astype tries to change the underlying type of your data, in this case, to category data, and you can further change this to ordinal data by parsing in an ordered flag set to true and parsing in the categories in an ordered fashion. So let's take a look at an example of this in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Grades\n",
       "excellent     A+\n",
       "excellent      A\n",
       "excellent     A-\n",
       "good          B+\n",
       "good           B\n",
       "good          B-\n",
       "ok            C+\n",
       "ok             C\n",
       "ok            C-\n",
       "poor          D+\n",
       "poor           D"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's bring in pandas as normal\n",
    "import pandas as pd\n",
    "\n",
    "# Here’s an example. Lets create a dataframe of letter grades in descending order. We can also set an index\n",
    "# value and here we'll just make it some human judgement of how good a student was, like \"excellent\" or \"good\"\n",
    "\n",
    "df=pd.DataFrame(['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D'],\n",
    "                index=['excellent', 'excellent', 'excellent', 'good', 'good', 'good', \n",
    "                       'ok', 'ok', 'ok', 'poor', 'poor'],\n",
    "               columns=[\"Grades\"])\n",
    "# let's create a DataFrame of letter grades in descending order. We can also set an index value, and here we'll just make it \n",
    "# some human judgment of how good a student was. So I just made these up, like excellent or good. So we just create our new \n",
    "# DataFrame and parse in all of our different letter grades, and then we set our index as normal to align with those letter \n",
    "# grades, and then to just say what we want it to be called. Let's take a look at that.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grades    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, if we check the datatype of this column, we see that it's just an object, since we set string values\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent    A+\n",
       "excellent     A\n",
       "excellent    A-\n",
       "good         B+\n",
       "good          B\n",
       "Name: Grades, dtype: category\n",
       "Categories (11, object): [A, A+, A-, B, ..., C+, C-, D, D+]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can, however, tell pandas that we want to change the type to category, using the astype() function\n",
    "df[\"Grades\"].astype(\"category\").head()\n",
    "# So the way we do this is we just put category in quotes to astype. It's a special string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent    A+\n",
       "excellent     A\n",
       "excellent    A-\n",
       "good         B+\n",
       "good          B\n",
       "Name: Grades, dtype: category\n",
       "Categories (11, object): [D < D+ < C- < C ... B+ < A- < A < A+]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see now that there are eleven categories, and pandas is aware of what those categories are. More\n",
    "# interesting though is that our data isn't just categorical, but that it's ordered. That is, an A- comes\n",
    "# after a B+, and B comes before a B+. We can tell pandas that the data is ordered by first creating a new\n",
    "# categorical data type with the list of the categories (in order) and the ordered=True flag\n",
    "my_categories=pd.CategoricalDtype(categories=['D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+'], \n",
    "                           ordered=True)\n",
    "# then we can just pass this to the astype() function instead of that string.\n",
    "grades=df[\"Grades\"].astype(my_categories)\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Grades\n",
       "ok       C+\n",
       "ok       C-\n",
       "poor     D+\n",
       "poor      D"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we see that pandas is not only aware that there are 11 categories, but it is also aware of the order of\n",
    "# those categoreies. So, what can you do with this? Well because there is an ordering this can help with\n",
    "# comparisons and boolean masking. For instance, if we have a list of our grades and we compare them to a “C”\n",
    "# we see that the lexicographical comparison returns results we were not intending. \n",
    "\n",
    "df[df[\"Grades\"]>\"C\"]\n",
    "# Remember, this is the one that isn't categorical data, these are just objects. We want a Boolean mask where the grades are \n",
    "# greater than a C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent    A+\n",
       "excellent     A\n",
       "excellent    A-\n",
       "good         B+\n",
       "good          B\n",
       "good         B-\n",
       "ok           C+\n",
       "Name: Grades, dtype: category\n",
       "Categories (11, object): [D < D+ < C- < C ... B+ < A- < A < A+]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So a C+ is great than a C, but a C- and D certainly are not. However, if we broadcast over the dataframe\n",
    "# which has the type set to an ordered categorical, we get the results we might expect.\n",
    "\n",
    "grades[grades>\"C\"]\n",
    "# Here are the grades DataFrame which is set with the correct categorical type and grades greater than C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that the operator works as we would expect. We can then use a certain set of mathematical operators,\n",
    "# like minimum, maximum, etc., on the ordinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes it is useful to represent categorical values as each being a column with a true or a false as to\n",
    "# whether the category applies. This is especially common in feature extraction, which is a topic in the data\n",
    "# mining course. Variables with a boolean value are typically called dummy variables, and pandas has a built\n",
    "# in function called get_dummies which will convert the values of a single column into multiple columns of\n",
    "# zeros and ones indicating the presence of the dummy variable. I rarely use it, but when I do it's very\n",
    "# handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STNAME\n",
       "Alabama        71339.343284\n",
       "Alaska         24490.724138\n",
       "Arizona       426134.466667\n",
       "Arkansas       38878.906667\n",
       "California    642309.586207\n",
       "Name: CENSUS2010POP, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There’s one more common scale-based operation I’d like to talk about, and that’s on converting a scale from\n",
    "# something that is on the interval or ratio scale, like a numeric grade, into one which is categorical. Now,\n",
    "# this might seem a bit counter intuitive to you, since you are losing information about the value. But it’s\n",
    "# commonly done in a couple of places. For instance, if you are visualizing the frequencies of categories,\n",
    "# this can be an extremely useful approach, and histograms are regularly used with converted interval or ratio\n",
    "# data. In addition, if you’re using a machine learning classification approach on data, you need to be using\n",
    "# categorical data, so reducing dimensionality may be useful just to apply a given technique. Pandas has a\n",
    "# function called cut which takes as an argument some array-like structure like a column of a dataframe or a\n",
    "# series. It also takes a number of bins to be used, and all bins are kept at equal spacing.\n",
    " \n",
    "# Lets go back to our census data for an example. We saw that we could group by state, then aggregate to get a\n",
    "# list of the average county size by state. If we further apply cut to this with, say, ten bins, we can see\n",
    "# the states listed as categoricals using the average county size.\n",
    "\n",
    "# let's bring in numpy\n",
    "import numpy as np\n",
    "\n",
    "# Now we read in our dataset\n",
    "df=pd.read_csv(\"datasets/census.csv\")\n",
    "\n",
    "# And we reduce this to county level data\n",
    "df=df[df['SUMLEV']==50] # We just want to take the sum level equals 50\n",
    "# And for a few groups\n",
    "df=df.set_index('STNAME').groupby(level=0)['CENSUS2010POP'].agg(np.average)\n",
    "# we'll look at just this census 2010 population. Let's look at the average values there. Let's look at the head of this.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STNAME\n",
       "Alabama                   (11706.087, 75333.413]\n",
       "Alaska                    (11706.087, 75333.413]\n",
       "Arizona                 (390320.176, 453317.529]\n",
       "Arkansas                  (11706.087, 75333.413]\n",
       "California              (579312.234, 642309.586]\n",
       "Colorado                 (75333.413, 138330.766]\n",
       "Connecticut             (390320.176, 453317.529]\n",
       "Delaware                (264325.471, 327322.823]\n",
       "District of Columbia    (579312.234, 642309.586]\n",
       "Florida                 (264325.471, 327322.823]\n",
       "Georgia                   (11706.087, 75333.413]\n",
       "Hawaii                  (264325.471, 327322.823]\n",
       "Idaho                     (11706.087, 75333.413]\n",
       "Illinois                 (75333.413, 138330.766]\n",
       "Indiana                   (11706.087, 75333.413]\n",
       "Iowa                      (11706.087, 75333.413]\n",
       "Kansas                    (11706.087, 75333.413]\n",
       "Kentucky                  (11706.087, 75333.413]\n",
       "Louisiana                 (11706.087, 75333.413]\n",
       "Maine                    (75333.413, 138330.766]\n",
       "Maryland                (201328.118, 264325.471]\n",
       "Massachusetts           (453317.529, 516314.881]\n",
       "Michigan                 (75333.413, 138330.766]\n",
       "Minnesota                 (11706.087, 75333.413]\n",
       "Mississippi               (11706.087, 75333.413]\n",
       "Missouri                  (11706.087, 75333.413]\n",
       "Montana                   (11706.087, 75333.413]\n",
       "Nebraska                  (11706.087, 75333.413]\n",
       "Nevada                  (138330.766, 201328.118]\n",
       "New Hampshire            (75333.413, 138330.766]\n",
       "New Jersey              (390320.176, 453317.529]\n",
       "New Mexico                (11706.087, 75333.413]\n",
       "New York                (264325.471, 327322.823]\n",
       "North Carolina           (75333.413, 138330.766]\n",
       "North Dakota              (11706.087, 75333.413]\n",
       "Ohio                     (75333.413, 138330.766]\n",
       "Oklahoma                  (11706.087, 75333.413]\n",
       "Oregon                   (75333.413, 138330.766]\n",
       "Pennsylvania            (138330.766, 201328.118]\n",
       "Rhode Island            (201328.118, 264325.471]\n",
       "South Carolina           (75333.413, 138330.766]\n",
       "South Dakota              (11706.087, 75333.413]\n",
       "Tennessee                 (11706.087, 75333.413]\n",
       "Texas                    (75333.413, 138330.766]\n",
       "Utah                     (75333.413, 138330.766]\n",
       "Vermont                   (11706.087, 75333.413]\n",
       "Virginia                  (11706.087, 75333.413]\n",
       "Washington              (138330.766, 201328.118]\n",
       "West Virginia             (11706.087, 75333.413]\n",
       "Wisconsin                (75333.413, 138330.766]\n",
       "Wyoming                   (11706.087, 75333.413]\n",
       "Name: CENSUS2010POP, dtype: category\n",
       "Categories (10, interval[float64]): [(11706.087, 75333.413] < (75333.413, 138330.766] < (138330.766, 201328.118] < (201328.118, 264325.471] ... (390320.176, 453317.529] < (453317.529, 516314.881] < (516314.881, 579312.234] < (579312.234, 642309.586]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if we just want to make \"bins\" of each of these, we can use cut()\n",
    "pd.cut(df,10) # let's say we want 10 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see that states like alabama and alaska fall into the same category, while california and the\n",
    "# disctrict of columbia fall in a very different category.\n",
    "\n",
    "# Now, cutting is just one way to build categories from your data, and there are many other methods. For\n",
    "# instance, cut gives you interval data, where the spacing between each category is equal sized. But sometimes\n",
    "# you want to form categories based on frequency – you want the number of items in each bin to the be the\n",
    "# same, instead of the spacing between bins. It really depends on what the shape of your data is, and what\n",
    "# you’re planning to do with it."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
